## Описание лабораторной работы
### Часть 1: Введение в сверточные нейронные сети (CNN) для классификации изображений
Цель: Научиться основам построения и обучения модели CNN для классификации изображений, используя PyTorch. Изучить архитектуру CNN, включая сверточные слои, пулинг и активационные функции.
### Выполненные этапы:
1.	Изучение базовой архитектуры CNN и её компонентов.
2.	Подготовка датасета CIFAR-10 для классификации изображений.
3.	Определение архитектуры сети с использованием сверточных и пулинг слоев.
4.	Обучение модели и оценка её точности.

### Часть 2: Классификация изображений с предобработкой и аугментацией данных
Цель: Понять влияние предобработки и аугментации данных на работу модели CNN. Изучить, как различные типы данных и аугментация помогают модели обобщать на разных выборках, таких как CIFAR-10, Fashion-MNIST и SVHN.
### Выполненные этапы:
1.	Подготовка данных из нескольких датасетов, применение разных методов аугментации (горизонтальное отражение, повороты, яркость).
2.	Обучение модели на каждом наборе данных и сравнение результатов.
3.	Проведение анализа, как аугментация влияет на обобщающую способность модели.

### Часть 3: Оптимизация архитектуры CNN
Цель: Изучить влияние изменения количества и размера фильтров, пулинг слоев, Batch Normalization и Dropout на производительность модели CNN. Оценить, как эти изменения влияют на переобучение и обобщающую способность модели.
### Выполненные этапы:
1.	Создание нескольких вариантов CNN с разными архитектурными параметрами (количество фильтров, размеры ядер, использование Batch Normalization и Dropout).
2.	Обучение и сравннение производительности моделей.
3.	Проведение анализа, как архитектурные параметры влияют на обобщение и точность модели.

### Часть 4: Оптимизация гиперпараметров с использованием нестандартных методов
Цель: Изучить влияние гиперпараметров, таких как learning rate, batch size и количество слоев. Применить методы циклического темпа обучения, адаптивного learning rate, динамического изменения batch size и анализировать, как эти гиперпараметры влияют на обучение.
### Выполненные этапы:
1.	Настройка базовых learning rate и batch size, применение Cyclic Learning Rate и Adaptive Learning Rate.
2.	Изучение влияния batch size и количества слоев на обучение.
3.	Сравнение результатов по разным стратегиям.



